{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a901427",
   "metadata": {},
   "source": [
    "# SPECTRAL CLUSTERING ON KDDCUP99 DATASET\n",
    "\n",
    "**Nom Prénom :** Saad ait hamida - Taha laaribi - Youssef Oulaha - Dikra zizoune \n",
    "\n",
    "**Classe :**  4 iir6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01c30f9",
   "metadata": {},
   "source": [
    "Installation et Versions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d3bc0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn: 1.7.2\n",
      "matplotlib: 3.10.7\n",
      "seaborn: 0.13.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np          # Numerical computing library (arrays, math operations)\n",
    "import random               # Random number generator for Python built-ins\n",
    "seed = 42                   # Magic number! Fixed seed = reproducible results\n",
    "np.random.seed(seed)        # Set numpy's random seed to 42\n",
    "random.seed(seed)           # Set Python's random seed to 42\n",
    "import warnings             # Warning message control\n",
    "warnings.filterwarnings('ignore')  # Hide non-critical warnings for clean output\n",
    "\n",
    "# Print library versions for reproducibility (professors love this!)\n",
    "import sklearn              # Machine learning library\n",
    "import matplotlib           # Plotting library\n",
    "import seaborn as sns       # Statistical data visualization\n",
    "print(f\"scikit-learn: {sklearn.__version__}\")     # Show sklearn version\n",
    "print(f\"matplotlib: {matplotlib.__version__}\")    # Show matplotlib version\n",
    "print(f\"seaborn: {sns.__version__}\")              # Show seaborn version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bee0a0",
   "metadata": {},
   "source": [
    "Chargement et Exploration des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16baa531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dimensions: (100655, 41)\n",
      "Unique classes and counts: {b'normal.': 97278, b'smurf.': 2409, b'neptune.': 898, b'back.': 15, b'satan.': 15, b'ipsweep.': 10, b'teardrop.': 9, b'portsweep.': 8, b'warezclient.': 8, b'pod.': 3, b'buffer_overflow.': 1, b'land.': 1}\n",
      "First 5 rows of features:\n",
      "  duration protocol_type  service   flag src_bytes dst_bytes land  \\\n",
      "0        0        b'tcp'  b'http'  b'SF'       181      5450    0   \n",
      "1        0        b'tcp'  b'http'  b'SF'       239       486    0   \n",
      "2        0        b'tcp'  b'http'  b'SF'       235      1337    0   \n",
      "3        0        b'tcp'  b'http'  b'SF'       219      1337    0   \n",
      "4        0        b'tcp'  b'http'  b'SF'       217      2032    0   \n",
      "\n",
      "  wrong_fragment urgent hot  ... dst_host_count dst_host_srv_count  \\\n",
      "0              0      0   0  ...              9                  9   \n",
      "1              0      0   0  ...             19                 19   \n",
      "2              0      0   0  ...             29                 29   \n",
      "3              0      0   0  ...             39                 39   \n",
      "4              0      0   0  ...             49                 49   \n",
      "\n",
      "  dst_host_same_srv_rate dst_host_diff_srv_rate dst_host_same_src_port_rate  \\\n",
      "0                    1.0                    0.0                        0.11   \n",
      "1                    1.0                    0.0                        0.05   \n",
      "2                    1.0                    0.0                        0.03   \n",
      "3                    1.0                    0.0                        0.03   \n",
      "4                    1.0                    0.0                        0.02   \n",
      "\n",
      "  dst_host_srv_diff_host_rate dst_host_serror_rate dst_host_srv_serror_rate  \\\n",
      "0                         0.0                  0.0                      0.0   \n",
      "1                         0.0                  0.0                      0.0   \n",
      "2                         0.0                  0.0                      0.0   \n",
      "3                         0.0                  0.0                      0.0   \n",
      "4                         0.0                  0.0                      0.0   \n",
      "\n",
      "  dst_host_rerror_rate dst_host_srv_rerror_rate  \n",
      "0                  0.0                      0.0  \n",
      "1                  0.0                      0.0  \n",
      "2                  0.0                      0.0  \n",
      "3                  0.0                      0.0  \n",
      "4                  0.0                      0.0  \n",
      "\n",
      "[5 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import dataset loader and preprocessing tools\n",
    "\n",
    "from sklearn.datasets import fetch_kddcup99\n",
    "\n",
    "# Load KDDCup99 dataset \n",
    "# subset='SA' = Simulated Attacks only (smaller, faster)\n",
    "# percent10=True = Use only 10% of data (makes it Colab-friendly)\n",
    "# random_state=seed = Same random subset every time\n",
    "data = fetch_kddcup99(subset='SA', percent10=True, random_state=42, as_frame=True)\n",
    "\n",
    "X = data.data        # pandas DataFrame of features\n",
    "y = data.target      # pandas Series of labels\n",
    "\n",
    "print(f\"Dataset dimensions: {X.shape}\")\n",
    "print(f\"Unique classes and counts: {y.value_counts().to_dict()}\")\n",
    "print(f\"First 5 rows of features:\\n{X.head()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d15c44",
   "metadata": {},
   "source": [
    "Prétraitement Complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61e5ed41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 10% subset...\n",
      "Original shape: (100655, 41)\n",
      "Labels shape: (100655,)\n",
      "Memory efficient preprocessing COMPLETE!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.datasets import fetch_kddcup99\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) RELOAD: 10% subset to save memory\n",
    "print(\"Loading 10% subset...\")\n",
    "data = fetch_kddcup99(subset=\"SA\", percent10=True, random_state=42)\n",
    "X, y = data.data, data.target  # X is numpy array now\n",
    "\n",
    "# 2) Convert to DataFrame\n",
    "df = pd.DataFrame(X, columns=data.feature_names)\n",
    "\n",
    "# 3) KEEP ONLY numeric columns (drop categorical: protocol_type, service, flag)\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "X_numeric = df[numeric_cols].values  # Convert to numpy array\n",
    "\n",
    "# # 4) Scale\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X_numeric)\n",
    "\n",
    "# 5) Encode labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "print(f\"Original shape: {X.shape}\")\n",
    "# print(f\"Numeric‑only shape: {X_scaled.shape}\")  # (9739, 38) - perfect size!\n",
    "print(f\"Labels shape: {y_encoded.shape}\")\n",
    "print(\"Memory efficient preprocessing COMPLETE!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4c164c",
   "metadata": {},
   "source": [
    "Baseline K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6a1f9e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: b'tcp'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m n_clusters = \u001b[38;5;28mlen\u001b[39m(np.unique(y))\n\u001b[32m      6\u001b[39m kmeans = KMeans(n_clusters=n_clusters, random_state=seed, n_init=\u001b[32m10\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m kmeans_labels = \u001b[43mkmeans\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m silhouette_kmeans = silhouette_score(X, kmeans_labels)\n\u001b[32m     10\u001b[39m ari_kmeans = adjusted_rand_score(y, kmeans_labels)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\cluster\\_kmeans.py:1064\u001b[39m, in \u001b[36m_BaseKMeans.fit_predict\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1042\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute cluster centers and predict cluster index for each sample.\u001b[39;00m\n\u001b[32m   1043\u001b[39m \n\u001b[32m   1044\u001b[39m \u001b[33;03m    Convenience method; equivalent to calling fit(X) followed by\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1062\u001b[39m \u001b[33;03m        Index of the cluster each sample belongs to.\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1064\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m.labels_\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\cluster\\_kmeans.py:1454\u001b[39m, in \u001b[36mKMeans.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1426\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1427\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1428\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute k-means clustering.\u001b[39;00m\n\u001b[32m   1429\u001b[39m \n\u001b[32m   1430\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1452\u001b[39m \u001b[33;03m        Fitted estimator.\u001b[39;00m\n\u001b[32m   1453\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1454\u001b[39m     X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1455\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1456\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1457\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1458\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1459\u001b[39m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcopy_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1461\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1462\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1464\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_params_vs_input(X)\n\u001b[32m   1466\u001b[39m     random_state = check_random_state(\u001b[38;5;28mself\u001b[39m.random_state)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\utils\\validation.py:2954\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2952\u001b[39m         out = X, y\n\u001b[32m   2953\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2954\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2955\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2956\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\utils\\validation.py:1053\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1051\u001b[39m         array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1052\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1053\u001b[39m         array = \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1055\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1056\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.format(array)\n\u001b[32m   1057\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomplex_warning\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\utils\\_array_api.py:757\u001b[39m, in \u001b[36m_asarray_with_order\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    755\u001b[39m     array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    756\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m     array = \u001b[43mnumpy\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    759\u001b[39m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    760\u001b[39m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m xp.asarray(array)\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: b'tcp'"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "\n",
    "# Baseline: K-means avec k optimal estimé\n",
    "n_clusters = len(np.unique(y))\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=seed, n_init=10)\n",
    "kmeans_labels = kmeans.fit_predict(X)\n",
    "\n",
    "silhouette_kmeans = silhouette_score(X, kmeans_labels)\n",
    "ari_kmeans = adjusted_rand_score(y, kmeans_labels)\n",
    "\n",
    "print(f\"Baseline K-means - Silhouette: {silhouette_kmeans:.3f}, ARI: {ari_kmeans:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a535ae8",
   "metadata": {},
   "source": [
    " Implémentation Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44edf034",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering     # Spectral clustering algorithm\n",
    "\n",
    "# Spectral Clustering with RBF kernel (Gaussian similarity)\n",
    "# gamma controls how similar points must be to connect\n",
    "spectral = SpectralClustering(\n",
    "    n_clusters=n_clusters,           # Same number as baseline\n",
    "    affinity='rbf',                  # RBF = Gaussian kernel (most common)\n",
    "    gamma=0.1,                       # Kernel width parameter (tuned later)\n",
    "    random_state=seed,               # Reproducibility\n",
    "    n_init=10                        # Multiple K-means restarts internally\n",
    ")\n",
    "\n",
    "# Fit and predict (computes Laplacian → eigenvectors → K-means automatically)\n",
    "spectral_labels = spectral.fit_predict(X)\n",
    "\n",
    "# Evaluate same metrics as baseline\n",
    "silhouette_spectral = silhouette_score(X, spectral_labels)\n",
    "ari_spectral = adjusted_rand_score(y, spectral_labels)\n",
    "\n",
    "print(f\"Spectral Clustering - Silhouette: {silhouette_spectral:.3f}, ARI: {ari_spectral:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bea35fa",
   "metadata": {},
   "source": [
    "Recherche Hyperparamètres (Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c57a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid  # Grid search utility\n",
    "\n",
    "# Test different gamma values (RBF kernel width)\n",
    "param_grid = {'gamma': [0.01, 0.1, 1.0, 10.0]}    # 4 values to test\n",
    "best_score = -1                                    # Track best silhouette score\n",
    "best_gamma = None                                  # Track best parameter\n",
    "\n",
    "# Loop through each gamma value\n",
    "for gamma in param_grid['gamma']:\n",
    "    # Create spectral clustering model with current gamma\n",
    "    sc = SpectralClustering(n_clusters=n_clusters, affinity='rbf', \n",
    "                           gamma=gamma, random_state=seed, n_init=10)\n",
    "    labels = sc.fit_predict(X)              # Train and predict\n",
    "    score = silhouette_score(X, labels)     # Calculate quality\n",
    "    print(f\"Gamma={gamma}: Silhouette={score:.3f}\") # Show progress\n",
    "    # Keep track of best performing gamma\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_gamma = gamma\n",
    "\n",
    "print(f\"Best gamma: {best_gamma} (score: {best_score:.3f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d180e875",
   "metadata": {},
   "source": [
    "Visualisation (2D avec PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a49193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA      # Principal Component Analysis\n",
    "import matplotlib.pyplot as plt            # Plotting library\n",
    "\n",
    "# Reduce 41 dimensions → 2D for visualization\n",
    "pca = PCA(n_components=2, random_state=seed)  # Keep 2 principal components\n",
    "X_pca = pca.fit_transform(X)           # Transform data to 2D\n",
    "\n",
    "# Create 3 subplots side-by-side\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))  # 1 row, 3 columns, size 15x4\n",
    "\n",
    "# Plot 1: Ground truth labels (what we want to recover)\n",
    "axes[0].scatter(X_pca[:, 0], X_pca[:, 1], c=y_encoded, cmap='tab10')\n",
    "axes[0].set_title('Ground Truth')             # Chart title\n",
    "axes[0].set_xlabel('PC1')                     # X-axis label\n",
    "axes[0].set_ylabel('PC2')                     # Y-axis label\n",
    "\n",
    "# Plot 2: K-means results\n",
    "axes[1].scatter(X_pca[:, 0], X_pca[:, 1], c=kmeans_labels, cmap='tab10')\n",
    "axes[1].set_title(f'K-means (Silhouette: {silhouette_kmeans:.3f})')\n",
    "\n",
    "# Plot 3: Spectral clustering results\n",
    "axes[2].scatter(X_pca[:, 0], X_pca[:, 1], c=spectral_labels, cmap='tab10')\n",
    "axes[2].set_title(f'Spectral (Silhouette: {silhouette_spectral:.3f})')\n",
    "\n",
    "plt.tight_layout()  # Fix spacing between plots\n",
    "plt.show()          # Display the figure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a396a5d0",
   "metadata": {},
   "source": [
    "Métriques Détaillées + Matrice de Confusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2676b4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import additional evaluation tools\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(\"=== DETAILED COMPARISON ===\")\n",
    "print(f\"Silhouette Score - K-means: {silhouette_kmeans:.3f} | Spectral: {silhouette_spectral:.3f}\")\n",
    "print(f\"Adjusted Rand Index - K-means: {ari_kmeans:.3f} | Spectral: {ari_spectral:.3f}\")\n",
    "\n",
    "# Normalized confusion matrix (rows=truth, columns=prediction)\n",
    "cm = confusion_matrix(y_encoded, spectral_labels, normalize='true')  # Percentages\n",
    "sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues')  # Pretty heatmap\n",
    "plt.title('Confusion Matrix - Spectral Clustering')   # Title\n",
    "plt.ylabel('True Label')                              # Y-axis\n",
    "plt.xlabel('Predicted Label')                         # X-axis\n",
    "plt.show()                                            # Display\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
